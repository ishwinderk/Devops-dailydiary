<meta http-equiv="Content-Type" content="text/html; charset=utf-8"><link type="text/css" rel="stylesheet" href="resources/sheet.css" >
<style type="text/css">.ritz .waffle a { color: inherit; }.ritz .waffle .s0{background-color:#ffffff;text-align:left;color:#000000;font-family:'Times New Roman';font-size:12pt;vertical-align:top;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s1{border-right: none;background-color:#ffffff;text-align:left;font-weight:bold;color:#000000;font-family:'Times New Roman';font-size:14pt;vertical-align:top;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}</style><div class="ritz grid-container" dir="ltr"><table class="waffle" cellspacing="0" cellpadding="0"><thead><tr><th class="row-header freezebar-origin-ltr"></th><th id="1740833494C0" style="width:1445px;" class="column-headers-background"></th></tr></thead><tbody><tr style="height: 584px"><th id="1740833494R0" style="height: 584px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 584px"></div></th><td class="s0" dir="ltr"><span style="font-size:14pt;font-weight:bold;">Day-3~ 13/7/23~ Thursday</span><span style="font-weight:bold;"><br><br></span><span style="font-size:14pt;font-weight:bold;">Docker </span><br>Docker is an open-source platform that allows developers to automate the deployment, scaling, and management of applications inside lightweight, portable containers. These containers bundle an application and all its dependencies, libraries, and runtime environment, ensuring consistency and reproducibility across different environments, such as development, testing, and production.<br><br><span style="font-weight:bold;">Here are the key components and concepts of Docker:<br></span><br><span style="font-weight:bold;">1. Container: </span>A container is a standalone, executable software package that includes everything needed to run a piece of software, including the code, runtime, libraries, and system tools. Containers are isolated from the host system and other containers, ensuring that an application runs consistently across various environments.<br><br><span style="font-weight:bold;">2. Docker Engine:</span> The core component of Docker, the Docker Engine, is responsible for running containers. It includes a server that listens for Docker API requests and a command-line interface (CLI) that allows users to interact with Docker.<br><br><span style="font-weight:bold;">3. Docker Image: </span>An image is a read-only template used to create containers. It contains the application code, libraries, dependencies, and other files required for an application to run. Images can be pulled from a central registry (such as Docker Hub) or created from a Dockerfile.<br><br><span style="font-weight:bold;">4. Dockerfile: </span>A Dockerfile is a text file that defines the configuration of a Docker image. It includes instructions on how to build the image, what base image to use, which files to include, environment variables, and other settings required for the application.<br><br><span style="font-weight:bold;">5. Docker Registry:</span> A Docker registry is a centralized repository that stores Docker images. Docker Hub is the default public registry, but organizations can also set up private registries to store and distribute their custom Docker images.<br><br><span style="font-weight:bold;">6. Containerization:</span> Containerization is the process of creating, running, and managing containers. Containers enable developers to package an application with all its dependencies, making it easier to move between different environments without encountering compatibility issues.<br><br>7<span style="font-weight:bold;">. Docker Compose: </span>Docker Compose is a tool used to define and manage multi-container Docker applications. It allows you to describe a complex application environment consisting of multiple services, networks, and volumes in a simple YAML file.<br><br><span style="font-weight:bold;">The benefits of using Docker include:</span><br><br><span style="font-weight:bold;">- Portability:</span> Docker containers can run on any platform that supports Docker, making it easy to move applications between development, testing, and production environments.<br><br><span style="font-weight:bold;">- Isolation: </span>Containers provide a high level of isolation, preventing application conflicts and dependency issues.<br><br><span style="font-weight:bold;">- Resource Efficiency:</span> Containers share the host OS&#39;s kernel, which makes them lightweight and resource-efficient compared to traditional virtual machines.<br><br><span style="font-weight:bold;">- Rapid Deployment:</span> Docker simplifies the deployment process, reducing the time it takes to bring an application into production.<br><br><span style="font-weight:bold;">- Version Control:</span> Docker images can be versioned, enabling developers to track changes to the application and its environment over time.<br><br><span style="font-weight:bold;">- Scalability:</span> Docker containers can be easily scaled up or down to handle varying workloads.<br><br>Overall, Docker has become an essential tool for developers and operations teams, streamlining the application development and deployment process and promoting a more consistent and reliable software delivery lifecycle.<br><br>Prerequesite : Any Programming language + Git<br><br><br><span style="font-size:14pt;font-weight:bold;">Container vs Virtual Machine<br><br></span>Containers and virtual machines (VMs) are both technologies used for virtualization, but they have some fundamental differences in how they work and what they offer. Here&#39;s a comparison of containers vs. virtual machines:<br><br><span style="font-weight:bold;">1. Technology:</span><br><br><span style="font-weight:bold;">- Containers:</span> Containers virtualize at the operating system (OS) level. They use the host OS&#39;s kernel and share its resources while isolating the application and its dependencies. Containers use features like namespaces and control groups (cgroups) to provide isolation and resource management.<br><span style="font-weight:bold;">- Virtual Machines:</span> VMs virtualize at the hardware level. They include a complete OS, along with the application and its dependencies, running on top of a hypervisor, which manages the VMs and isolates them from the host system.<br><br><span style="font-weight:bold;">2. Isolation:</span><br><br><span style="font-weight:bold;">- Containers:</span> Containers offer lightweight isolation, isolating the application and its dependencies from other containers and the host system. However, they share the same OS kernel, which means if there&#39;s a kernel-level vulnerability, it can affect all containers running on that host.<br><span style="font-weight:bold;">- Virtual Machines:</span> VMs provide stronger isolation since each VM has its own full-fledged OS, and any vulnerability in one VM doesn&#39;t directly affect others or the host system.<br><br><span style="font-weight:bold;">3. Resource Overhead:<br><br>- Containers:</span> Containers have minimal overhead because they share the host OS&#39;s kernel and don&#39;t require separate OS instances for each container. This makes them highly resource-efficient and faster to start and stop.<br><span style="font-weight:bold;">- Virtual Machines:</span> VMs have more overhead due to running a separate OS instance for each VM. This can lead to higher resource consumption and longer startup times compared to containers.<br><br><span style="font-weight:bold;">4. Portability:</span><br><br><span style="font-weight:bold;">- Containers:</span> Containers are highly portable because they encapsulate the application and its dependencies, making it easier to run the same containerized application across different environments.<br><span style="font-weight:bold;">- Virtual Machines: </span>VMs are also portable, but they tend to be bulkier due to including a complete OS, which can make them less agile in some scenarios.<br><br><span style="font-weight:bold;">5. Use Cases:</span><br><br><span style="font-weight:bold;">- Containers: </span>Containers are ideal for microservices architecture, where applications are broken down into smaller, independent services. They are also well-suited for cloud-native applications, continuous integration/continuous deployment (CI/CD) pipelines, and scenarios where rapid scaling and deployment are required.<br><span style="font-weight:bold;">- Virtual Machines:</span> VMs are well-suited for applications that require strong isolation and where different operating systems are needed for specific purposes. Legacy applications that aren&#39;t easily containerized can also benefit from virtualization.<br><br>In summary, containers are generally more lightweight, faster to start and stop, and offer easier portability, making them a preferred choice for many modern applications. On the other hand, virtual machines provide stronger isolation and are better suited for specific use cases that require multiple OS instances and stronger separation between applications. In practice, many organizations use both technologies in combination, leveraging their respective strengths for different parts of their infrastructure.<br><br></td></tr><tr style="height: 512px"><th id="1740833494R1" style="height: 512px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 512px"></div></th><td class="s1 softmerge" dir="ltr"><div class="softmerge-inner" style="width:3543px;left:-1px"><span style="font-size:12pt;">Docker Architecture<br></span><span style="font-size:12pt;font-weight:normal;">Docker&#39;s architecture is based on a client-server model and consists of several components that work together to enable the creation, management, and execution of containers. The main components of Docker&#39;s architecture are as follows:<br><br></span><span style="font-size:12pt;">1.Docker Client:</span><span style="font-size:12pt;font-weight:normal;"> The Docker client is the primary interface through which users interact with Docker. It provides a command-line interface (CLI) and APIs that allow users to issue commands to the Docker daemon. The client can run on the same host as the Docker daemon or connect to a remote Docker daemon.<br><br></span><span style="font-size:12pt;">2.Docker Daemon:</span><span style="font-size:12pt;font-weight:normal;"> The Docker daemon, also known as the Docker Engine, is the core server-side component responsible for managing Docker objects like images, containers, volumes, networks, etc. It listens for Docker API requests from the Docker client and takes care of building, running, and managing containers. The daemon manages all container-related tasks, including container execution, networking, and storage.<br><br></span><span style="font-size:12pt;">3.Docker Images: </span><span style="font-size:12pt;font-weight:normal;">Docker images are read-only templates that contain the application code, runtime, libraries, dependencies, and other files required to run an application. Images are created either manually or using a Dockerfile and serve as the basis for creating containers. They are stored in a registry (e.g., Docker Hub) and can be shared among users and teams.<br><br></span><span style="font-size:12pt;">4.Docker Containers:</span><span style="font-size:12pt;font-weight:normal;"> Containers are instances of Docker images. They encapsulate the application and its dependencies, running in an isolated environment. Containers are lightweight and can be started, stopped, and moved between different environments with ease. Each container runs as a separate process, isolated from other containers and the host system.<br><br></span><span style="font-size:12pt;">5.Docker Registries:</span><span style="font-size:12pt;font-weight:normal;"> Docker registries are repositories that store Docker images. Docker Hub is the default public registry provided by Docker, where users can find a vast collection of pre-built images. Organizations can also set up private registries to store and distribute their custom images, ensuring greater control over image distribution and access.<br><br></span><span style="font-size:12pt;">6.Docker Compose:</span><span style="font-size:12pt;font-weight:normal;"> Docker Compose is a tool that allows users to define and manage multi-container Docker applications using a YAML file. It simplifies the process of defining and orchestrating complex applications with multiple services, networks, and volumes.<br><br></span><span style="font-size:12pt;">7.Docker Volumes: </span><span style="font-size:12pt;font-weight:normal;">Docker volumes are used to persist data generated by and used by containers. Volumes allow data to be stored outside the container&#39;s writable layer, ensuring that the data persists even if the container is removed or replaced. This is useful for scenarios where data needs to be shared and accessed between containers or where data needs to survive container restarts.<br><br></span><span style="font-size:12pt;">The typical workflow in Docker involves the following steps:</span><span style="font-size:12pt;font-weight:normal;"><br><br>1. Create a Docker image either manually or using a Dockerfile.<br>2. Use the Docker client to interact with the Docker daemon, which then builds, runs, and manages containers based on the specified images.<br>3. Containers are launched from images, and applications run inside these containers.<br>4. If needed, data can be stored in Docker volumes to ensure persistence.<br>5. Docker images and containers can be pushed to and pulled from Docker registries for sharing with others.<br><br>Docker&#39;s modular architecture and extensive ecosystem have made it a popular choice for containerization, enabling developers to build, ship, and run applications seamlessly across different environments.<br><br></span><span style="font-size:12pt;">Task - </span><span style="font-size:12pt;font-weight:normal;">Different types of APIs with its needAPIs (Application Programming Interfaces) are sets of rules and protocols that allow different software applications to communicate and interact with each other. They play a crucial role in modern software development by enabling the integration and interoperability of various systems, services, and data sources. There are different types of APIs, each serving specific needs and use cases. Here are some common types of APIs and their purposes:<br><br></span><span style="font-size:12pt;">1. Web APIs (HTTP APIs):</span><span style="font-size:12pt;font-weight:normal;"><br>   - Purpose: Web APIs, also known as HTTP APIs, are interfaces exposed over the internet, typically using HTTP(S) protocols. They allow different software systems to communicate and interact with web servers. Web APIs are used to access and manipulate data, perform actions, and retrieve information from remote servers or web services.<br>   - Need: Web APIs are essential for enabling web applications and mobile apps to interact with external services, such as social media APIs (e.g., Twitter API, Facebook Graph API), payment gateways, weather data providers, and more.<br><br></span><span style="font-size:12pt;">2. RESTful APIs (Representational State Transfer):</span><span style="font-size:12pt;font-weight:normal;"><br>   - Purpose: RESTful APIs are a type of web API that follows the principles of REST architecture. They use standard HTTP methods (GET, POST, PUT, DELETE) to perform CRUD (Create, Read, Update, Delete) operations on resources. RESTful APIs are designed to be simple, scalable, and stateless.<br>   - Need: RESTful APIs are widely used for building web services that can be consumed by various clients, such as web browsers, mobile apps, and IoT devices. They are commonly used for cloud services, social media platforms, and general-purpose web APIs.<br><br></span><span style="font-size:12pt;">3. SOAP APIs (Simple Object Access Protocol):</span><span style="font-size:12pt;font-weight:normal;"><br>   - Purpose: SOAP APIs are a protocol-based approach for creating web services. They use XML as their message format and are often more rigid and complex compared to RESTful APIs. SOAP APIs are used in enterprise-level applications and scenarios where strict protocols and standards are required.<br>   - Need: SOAP APIs are commonly used in enterprise systems, where security, reliability, and transactional support are crucial. They are prevalent in scenarios like financial systems, healthcare applications, and business-to-business (B2B) integrations.<br><br></span><span style="font-size:12pt;">4. GraphQL APIs</span><span style="font-size:12pt;font-weight:normal;"><br>   - Purpose: GraphQL is a query language and runtime for APIs. It allows clients to request the exact data they need and no more, reducing over-fetching and under-fetching of data. GraphQL APIs offer a more flexible and efficient approach compared to traditional RESTful APIs.<br>   - Need: GraphQL APIs are useful in scenarios where client applications have specific data requirements or where the server-side schema might evolve frequently. They are popular in modern web and mobile app development.<br><br></span><span style="font-size:12pt;">5. Library APIs:</span><span style="font-size:12pt;font-weight:normal;"><br>   - Purpose: Library APIs, also known as SDKs (Software Development Kits), are collections of functions, classes, and methods provided by software libraries. They offer pre-built functionality for developers to integrate into their applications.<br>   - Need: Library APIs are used to simplify and accelerate the development process. They are prevalent in software development for various programming languages and platforms, providing access to functionalities like database operations, file handling, and graphical user interfaces.<br><br></span><span style="font-size:12pt;">6. Hardware APIs:</span><span style="font-size:12pt;font-weight:normal;"><br>   - Purpose: Hardware APIs allow software applications to communicate with hardware devices, such as printers, graphics cards, sensors, and other peripherals.<br>   - Need: Hardware APIs enable developers to build applications that can take advantage of specific hardware capabilities and interact with physical devices. These APIs are crucial in fields like IoT, robotics, and device driver development.<br><br>APIs are foundational in modern software development, promoting reusability, interoperability, and collaboration between different software components and services. They enable developers to build powerful applications by leveraging functionalities provided by external services and libraries, making it easier to focus on core features rather than reinventing the wheel.</span></div></td></tr></tbody></table></div>